{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Text Classification Generalised Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "# Text analtical Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import itertools \n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Word Cloud\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For saving the model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Location of the CSV dataset\n",
    "#FILE_PATH = r'./LnT/train_set.csv'\n",
    "#FILE_DELIMETER = ','"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dataset = pd.read_csv(FILE_PATH,delimiter=FILE_DELIMETER,engine='python')\n",
    "dataset = pd.read_excel('./LnT/train_set.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocssing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessingData(data):\n",
    "    # drop null values\n",
    "    data.dropna(inplace=True)\n",
    "    # remove duplicate rows\n",
    "    data.drop_duplicates(inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line by Line Text Cleaning using NLP libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer initialization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tokenizer initialization\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "# Expression for @mailaddress.com\n",
    "exp1 = r'@[A-Za-z0-9_]+'\n",
    "\n",
    "# Expression for URLs\n",
    "exp2 = r'https?://[^ ]+'\n",
    "\n",
    "#Expression for special characters\n",
    "exp3 = r'[^0-9A-Za-z \\t]'\n",
    "\n",
    "combined_pat = r'|'.join((exp1, exp2,exp3))\n",
    "\n",
    "#Expression for URL www.\n",
    "www_pattern = r'www.[^ ]+'\n",
    "\n",
    "# Dictinory for manuplating text\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "all_words = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    \n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    \n",
    "    stripped = re.sub(www_pattern, '', stripped)\n",
    "    \n",
    "    lower_case = stripped.lower()\n",
    "    \n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    \n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    \n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    words = [x for x  in tok.tokenize(neg_handled) if len(x) > 1]\n",
    "    after_removing_stop_words = [word for word in words if word not in (stop_words)]\n",
    "    \n",
    "    # Replace abbreviations and some spell correction\n",
    "    after_lemmatizer = []\n",
    "    for word in after_removing_stop_words:\n",
    "        word=lemmatizer.lemmatize(word)\n",
    "        all_words.append(word)\n",
    "        after_lemmatizer.append(word)\n",
    "        \n",
    "    return(\" \".join(after_lemmatizer)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCloud(all_words):\n",
    "    all_words_freq = nltk.FreqDist(all_words)\n",
    "    word_cloud_words = list(filter(lambda x:x[1]>=50,all_words_freq.items()))\n",
    "    word_cloud = []\n",
    "    for key,value in word_cloud_words:\n",
    "        word_cloud.append(key)   \n",
    "\n",
    "    wordcloud = WordCloud(width = 1000, height = 1000,background_color='black')\n",
    "\n",
    "    wordcloud.generate(str(word_cloud))\n",
    "    plt.figure(figsize = (8, 8), facecolor = None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "    plt.title('Word Cloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "###**convert text tu number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurePrepration(data):\n",
    "    documents = []\n",
    "    for index,row in data.iterrows():\n",
    "        documents.append((text_cleaner(row.text),row.category))\n",
    "    \n",
    "    random.shuffle(documents)\n",
    "    \n",
    "    dataframe = pd.DataFrame(documents,columns=['text','category']) \n",
    "    \n",
    "    \n",
    "    #wordCloud(all_words)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "def plot_confusion_matrix(cm,target_names,title):\n",
    "    cmap=None\n",
    "    normalize=False\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dkm20\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dkm20\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "data = preProcessingData(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total feature preparation by cleaning each text\n",
    "data = featurePrepration(data)\n",
    "# Showing wordCloud below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WORK CATEGORY : Formwork. APPLICATION : Constr...</td>\n",
       "      <td>Shuttering Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WORK CATEGORY : Formwork. SCOPE OF WORK : Maki...</td>\n",
       "      <td>Shuttering Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WORK CATEGORY : Formwork. APPLICATION : For ge...</td>\n",
       "      <td>Shuttering Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WORK GROUP:-Fixing of shuttering;SCOPE:-Fixing...</td>\n",
       "      <td>Shuttering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Construction of concrete structure; TYPE OF ST...</td>\n",
       "      <td>Shuttering Work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text         category\n",
       "0   WORK CATEGORY : Formwork. APPLICATION : Constr...  Shuttering Work\n",
       "1   WORK CATEGORY : Formwork. SCOPE OF WORK : Maki...  Shuttering Work\n",
       "2   WORK CATEGORY : Formwork. APPLICATION : For ge...  Shuttering Work\n",
       "3   WORK GROUP:-Fixing of shuttering;SCOPE:-Fixing...       Shuttering\n",
       "20  Construction of concrete structure; TYPE OF ST...  Shuttering Work"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test Spliting, Test dataset has taken 30% for validation\n",
    "x = data['text']\n",
    "y = data['category']\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,stratify=y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-Idf feature set creation\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=300)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training by using Random Forest Algorithm\n",
    "textClassifierRandomForest = RandomForestClassifier(n_estimators=300)\n",
    "textClassifierRandomForest.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels_rf = textClassifierRandomForest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = textClassifierRandomForest.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model - 56.0%\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of the model - '+str(round(accuracy*100,2))+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix to understand the results\n",
    "classes = list(y_test.unique())\n",
    "c_matrix = confusion_matrix(y_test,predicted_labels_rf,labels=classes)\n",
    "#plot_confusion_matrix(np.array(c_matrix),classes,\"Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest is giving the accuracy of  test dataset, For using the same model in future we are retraining the model on complete dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Retraining on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 2)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Complete dataset is already cleaned and processed\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scope cement flooring work categorization char...</td>\n",
       "      <td>Concreting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scope asorted activity</td>\n",
       "      <td>Concreting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scope placing concrete using stationary concre...</td>\n",
       "      <td>Concreting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scope placing concrete method type concrete re...</td>\n",
       "      <td>Concreting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>work groupsupporting activitiesscopeerection s...</td>\n",
       "      <td>Shuttering Work\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           category\n",
       "0  scope cement flooring work categorization char...         Concreting\n",
       "1                             scope asorted activity         Concreting\n",
       "2  scope placing concrete using stationary concre...         Concreting\n",
       "3  scope placing concrete method type concrete re...         Concreting\n",
       "4  work groupsupporting activitiesscopeerection s...  Shuttering Work\\n"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['text']\n",
    "y = data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tf-Idf feature set creation\n",
    "vectorizer_final = TfidfVectorizer(stop_words='english')\n",
    "x_train_all = vectorizer_final.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=300)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training by using Random Forest Algorithm\n",
    "textClassifierRandomForestModel = RandomForestClassifier(n_estimators=300)\n",
    "textClassifierRandomForestModel.fit(x_train_all,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pickle files of model and Tf-idf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tf-idf matrix for future predictions\n",
    "filename = open('./LnT/IfIdf_matrix.pkl','wb')\n",
    "pickle.dump(vectorizer_final,filename)\n",
    "filename.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for future predictions\n",
    "filename = open('./LnT/textClassifierRandomForestModel.pkl','wb')\n",
    "pickle.dump(textClassifierRandomForestModel,filename)\n",
    "filename.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model on Unseen Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the unseen dataset\n",
    "newDatset = pd.read_excel('./LnT/test_set.xlsx', sheet_name='Sheet1')\n",
    "#newDatset = pd.read_csv('./LnT/test_set.csv',engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WORK CATEGORY : Formwork. APPLICATION : Constr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Labour charges for Fixing &amp; Removing of shutte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SCOPE :- Assembly of straight slipform; HEIGHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SCOPE :- Slipform concreting; Work Categorizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SCOPE :- Cutting, bending and tying of rebar i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  WORK CATEGORY : Formwork. APPLICATION : Constr...\n",
       "1  Labour charges for Fixing & Removing of shutte...\n",
       "2  SCOPE :- Assembly of straight slipform; HEIGHT...\n",
       "3  SCOPE :- Slipform concreting; Work Categorizat...\n",
       "4  SCOPE :- Cutting, bending and tying of rebar i..."
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newDatset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the text\n",
    "documents_unseen = []\n",
    "for index,row in newDatset.iterrows():\n",
    "    documents_unseen.append((text_cleaner(row.text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_cleaned_data =  pd.DataFrame(documents_unseen,columns=['cleaned_text'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_cleaned_data['text'] = newDatset.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = unseen_cleaned_data['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved pickle of matrix\n",
    "filename = open('./LnT/IfIdf_matrix.pkl','rb')\n",
    "vectorizer = pickle.load(filename)\n",
    "filename.close()\n",
    "\n",
    "# Tranform the deatures\n",
    "newDatset_vectorised = vectorizer.transform(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "filename = open('./LnT/textClassifierRandomForestModel.pkl','rb')\n",
    "textClassifierRandomForest = pickle.load(filename)\n",
    "filename.close()\n",
    "\n",
    "#Predict the result on unseen data\n",
    "predicted_newDataset_labels = textClassifierRandomForest.predict(newDatset_vectorised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the result in dataframe\n",
    "result = pd.DataFrame()\n",
    "result['category'] = predicted_newDataset_labels\n",
    "result['text'] = unseen_cleaned_data.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shuttering Work</td>\n",
       "      <td>WORK CATEGORY : Formwork. APPLICATION : Constr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shuttering Work</td>\n",
       "      <td>Labour charges for Fixing &amp; Removing of shutte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Slipform Shuttering Work</td>\n",
       "      <td>SCOPE :- Assembly of straight slipform; HEIGHT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slipform Shuttering Work</td>\n",
       "      <td>SCOPE :- Slipform concreting; Work Categorizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Slipform Shuttering Work</td>\n",
       "      <td>SCOPE :- Cutting, bending and tying of rebar i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Slipform Shuttering Work</td>\n",
       "      <td>SCOPE:-Operation of straight slipform;HEIGHT:-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Slipform Shuttering Work</td>\n",
       "      <td>SCOPE:-Erection of stair tower;HEIGHT:-0 to 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shuttering\\n</td>\n",
       "      <td>SCOPE :- Labour charges for fixing and removin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shuttering\\n</td>\n",
       "      <td>SCOPE :- Labour Charges for shutter Making wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shuttering\\n</td>\n",
       "      <td>SCOPE :- As described further; Labour Charges ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shuttering</td>\n",
       "      <td>SCOPE :- Material shifting; TYPE OF MATERIAL/W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shuttering Work\\n</td>\n",
       "      <td>WORK GROUP:-Fixing of shuttering;SCOPE:-Fixing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Shuttering Work\\n</td>\n",
       "      <td>SCOPE :- Formwork making; TYPE :- Shutter boar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Shuttering Work\\n</td>\n",
       "      <td>SCOPE :- Fixing &amp; removing of shutter includin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Shuttering</td>\n",
       "      <td>WORK GROUP:-Supporting activities;SCOPE:-Fixin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Shuttering</td>\n",
       "      <td>SCOPE :- Removing of shuttering; TYPE :- Found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Shuttering</td>\n",
       "      <td>SCOPE :- Fixing of shuttering; TYPE :- Beams &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Shuttering</td>\n",
       "      <td>SCOPE :- Fixing of shuttering; TYPE :- Beams &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Concrete\\n</td>\n",
       "      <td>SCOPE :- Lowering into trench, laying, alignin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Concrete\\n</td>\n",
       "      <td>Construction of concrete structure; TYPE OF ST...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    category  \\\n",
       "0            Shuttering Work   \n",
       "1            Shuttering Work   \n",
       "2   Slipform Shuttering Work   \n",
       "3   Slipform Shuttering Work   \n",
       "4   Slipform Shuttering Work   \n",
       "5   Slipform Shuttering Work   \n",
       "6   Slipform Shuttering Work   \n",
       "7               Shuttering\\n   \n",
       "8               Shuttering\\n   \n",
       "9               Shuttering\\n   \n",
       "10                Shuttering   \n",
       "11         Shuttering Work\\n   \n",
       "12         Shuttering Work\\n   \n",
       "13         Shuttering Work\\n   \n",
       "14                Shuttering   \n",
       "15                Shuttering   \n",
       "16                Shuttering   \n",
       "17                Shuttering   \n",
       "18                Concrete\\n   \n",
       "19                Concrete\\n   \n",
       "\n",
       "                                                 text  \n",
       "0   WORK CATEGORY : Formwork. APPLICATION : Constr...  \n",
       "1   Labour charges for Fixing & Removing of shutte...  \n",
       "2   SCOPE :- Assembly of straight slipform; HEIGHT...  \n",
       "3   SCOPE :- Slipform concreting; Work Categorizat...  \n",
       "4   SCOPE :- Cutting, bending and tying of rebar i...  \n",
       "5   SCOPE:-Operation of straight slipform;HEIGHT:-...  \n",
       "6   SCOPE:-Erection of stair tower;HEIGHT:-0 to 10...  \n",
       "7   SCOPE :- Labour charges for fixing and removin...  \n",
       "8   SCOPE :- Labour Charges for shutter Making wit...  \n",
       "9   SCOPE :- As described further; Labour Charges ...  \n",
       "10  SCOPE :- Material shifting; TYPE OF MATERIAL/W...  \n",
       "11  WORK GROUP:-Fixing of shuttering;SCOPE:-Fixing...  \n",
       "12  SCOPE :- Formwork making; TYPE :- Shutter boar...  \n",
       "13  SCOPE :- Fixing & removing of shutter includin...  \n",
       "14  WORK GROUP:-Supporting activities;SCOPE:-Fixin...  \n",
       "15  SCOPE :- Removing of shuttering; TYPE :- Found...  \n",
       "16  SCOPE :- Fixing of shuttering; TYPE :- Beams &...  \n",
       "17  SCOPE :- Fixing of shuttering; TYPE :- Beams &...  \n",
       "18  SCOPE :- Lowering into trench, laying, alignin...  \n",
       "19  Construction of concrete structure; TYPE OF ST...  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(20).reset_index(drop='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the output prediction in csv file\n",
    "result.to_excel('./LnT/predictedCategories.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
